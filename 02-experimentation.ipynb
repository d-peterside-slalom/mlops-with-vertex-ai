{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eae86f7",
   "metadata": {},
   "source": [
    "# 02 - ML Experimentation with Custom Model\n",
    "\n",
    "The purpose of this notebook is to use [custom training](https://cloud.google.com/ai-platform-unified/docs/training/custom-training) to train a keras classifier to predict whether a given trip will result in a tip > 20%. The notebook covers the following tasks:\n",
    "1. Preprocess the data locally using Apache Beam.\n",
    "2. Train and test custom model locally using a Keras implementation.\n",
    "3. Submit a Dataflow job to preprocess the data at scale.\n",
    "4. Submit a custom training job to Vertex AI using a [pre-built container](https://cloud.google.com/ai-platform-unified/docs/training/pre-built-containers).\n",
    "5. Upload the trained model to Vertex AI.\n",
    "6. Track experiment parameters from [Vertex AI Metadata](https://cloud.google.com/vertex-ai/docs/ml-metadata/introduction).\n",
    "7. Submit a [hyperparameter tuning job](https://cloud.google.com/vertex-ai/docs/training/hyperparameter-tuning-overview) to Vertex AI.\n",
    "\n",
    "We use [Vertex TensorBoard](https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-overview) \n",
    "and [Vertex ML Metadata](https://cloud.google.com/vertex-ai/docs/ml-metadata/introduction) to  track, visualize, and compare ML experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5205917",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624c6cfe",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4171d42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 01:46:54.518188: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-18 01:46:55.466169: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-05-18 01:46:55.466265: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-05-18 01:46:55.466275: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.11.0\n",
      "TensorFlow Transform: 1.12.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "# from collections.abc import Mapping\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud.aiplatform import hyperparameter_tuning as hp_tuning\n",
    "\n",
    "from src.common import features, datasource_utils\n",
    "from src.model_training import data, model, defaults, trainer, exporter\n",
    "from src.preprocessing import etl\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "tf.get_logger().setLevel('INFO')\n",
    "\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(f\"TensorFlow Transform: {tft.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde361cf",
   "metadata": {},
   "source": [
    "### Setup Google Cloud project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31fce242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID: g360-docai\n",
      "Region: us-west1\n",
      "Bucket name: vertex-mlops-chicago-taxi-bucket\n",
      "Bucket URI: gs://vertex-mlops-chicago-taxi-bucket\n",
      "Service Account: 956259099845-compute@developer.gserviceaccount.com\n",
      "Vertex API Parent URI: projects/g360-docai/locations/us-west1\n"
     ]
    }
   ],
   "source": [
    "PROJECT = 'g360-docai' # Change to your project id.\n",
    "REGION = 'us-west1' # Change to your region.\n",
    "BUCKET = 'vertex-mlops-chicago-taxi-bucket' # Change to your bucket name.\n",
    "BUCKET_URI = f\"gs://{BUCKET}\" \n",
    "SERVICE_ACCOUNT = \"956259099845-compute@developer.gserviceaccount.com\"\n",
    "\n",
    "if PROJECT == \"\" or PROJECT is None or PROJECT == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT = shell_output[0]\n",
    "    \n",
    "if SERVICE_ACCOUNT == \"\" or SERVICE_ACCOUNT is None or SERVICE_ACCOUNT == \"[your-service-account]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = !gcloud config list --format 'value(core.account)' 2>/dev/null\n",
    "    SERVICE_ACCOUNT = shell_output[0]\n",
    "    \n",
    "if BUCKET == \"\" or BUCKET is None or BUCKET == \"[your-bucket-name]\":\n",
    "    # Get your bucket name to GCP projet id\n",
    "    BUCKET = PROJECT\n",
    "    # Try to create the bucket if it doesn'exists\n",
    "    ! gsutil mb -l $REGION gs://$BUCKET\n",
    "    print(\"\")\n",
    "    \n",
    "PARENT = f\"projects/{PROJECT}/locations/{REGION}\"\n",
    "    \n",
    "print(\"Project ID:\", PROJECT)\n",
    "print(\"Region:\", REGION)\n",
    "print(\"Bucket name:\", BUCKET)\n",
    "print(\"Bucket URI:\", BUCKET_URI)\n",
    "print(\"Service Account:\", SERVICE_ACCOUNT)\n",
    "print(\"Vertex API Parent URI:\", PARENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cfd33f",
   "metadata": {},
   "source": [
    "### Set configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b363e822",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = \"v01\"\n",
    "DATASET_DISPLAY_NAME = \"chicago-taxi-tips\"\n",
    "MODEL_DISPLAY_NAME = f'{DATASET_DISPLAY_NAME}-classifier-{VERSION}'\n",
    "\n",
    "WORKSPACE = f\"gs://{BUCKET}/{DATASET_DISPLAY_NAME}\"\n",
    "EXPERIMENT_ARTIFACTS_DIR = os.path.join(WORKSPACE, \"experiments\")\n",
    "RAW_SCHEMA_LOCATION = \"src/raw_schema/schema.pbtxt\"\n",
    "\n",
    "TENSORBOARD_DISPLAY_NAME = f\"tb-{DATASET_DISPLAY_NAME}\"\n",
    "EXPERIMENT_NAME = f\"{MODEL_DISPLAY_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cf63d9",
   "metadata": {},
   "source": [
    "## Create Vertex TensorBoard instance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cf8ef5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Tensorboard\n",
      "Create Tensorboard backing LRO: projects/956259099845/locations/us-central1/tensorboards/4242487606006251520/operations/4167866157010780160\n",
      "Tensorboard created. Resource name: projects/956259099845/locations/us-central1/tensorboards/4242487606006251520\n",
      "To use this Tensorboard in another session:\n",
      "tb = aiplatform.Tensorboard('projects/956259099845/locations/us-central1/tensorboards/4242487606006251520')\n",
      "TensorBoard resource name: projects/956259099845/locations/us-central1/tensorboards/4242487606006251520\n"
     ]
    }
   ],
   "source": [
    "tensorboard_resource = vertex_ai.Tensorboard.create(display_name=TENSORBOARD_DISPLAY_NAME)\n",
    "tensorboard_resource_name = tensorboard_resource.gca_resource.name\n",
    "print(\"TensorBoard resource name:\", tensorboard_resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670a3859",
   "metadata": {},
   "source": [
    "## Initialize workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a90aab80-196d-4f30-a729-eb8f4a23a95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket vertex-mlops-chicago-taxi-bucket already exists\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "def bucket_check(bucket_name):\n",
    "    \"\"\"Creates a new bucket.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    \n",
    "    # Check if the bucket already exists\n",
    "    if not storage_client.lookup_bucket(bucket_name):\n",
    "        bucket = storage_client.create_bucket(bucket_name)\n",
    "        print(\"Bucket {} created\".format(bucket.name))\n",
    "    else:\n",
    "        print(\"Bucket {} already exists\".format(bucket_name))\n",
    "\n",
    "        \n",
    "bucket_check(BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d03fba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new experiment artifacts directory...\n",
      "Workspace is ready.\n",
      "Experiment directory: gs://vertex-mlops-chicago-taxi-bucket/chicago-taxi-tips/experiments\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "REMOVE_EXPERIMENT_ARTIFACTS = False\n",
    "if tf.io.gfile.exists(EXPERIMENT_ARTIFACTS_DIR) and REMOVE_EXPERIMENT_ARTIFACTS:\n",
    "    print(\"Removing previous experiment artifacts...\")\n",
    "    tf.io.gfile.rmtree(PATH(EXPERIMENT_ARTIFACTS_DIR))\n",
    "\n",
    "if not tf.io.gfile.exists(EXPERIMENT_ARTIFACTS_DIR):\n",
    "    print(\"Creating new experiment artifacts directory...\")\n",
    "    tf.io.gfile.makedirs(Path(EXPERIMENT_ARTIFACTS_DIR))\n",
    "\n",
    "print(\"Workspace is ready.\")\n",
    "print(\"Experiment directory:\", EXPERIMENT_ARTIFACTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd08e503",
   "metadata": {},
   "source": [
    "## Initialize Vertex AI experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3aefc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associating projects/956259099845/locations/us-west1/metadataStores/default/contexts/chicago-taxi-tips-classifier-v01-run-local-20230518014659 to Experiment: chicago-taxi-tips-classifier-v01\n",
      "Experiment run directory: gs://vertex-mlops-chicago-taxi-bucket/chicago-taxi-tips/experiments/chicago-taxi-tips-classifier-v01/run-local-20230518014659\n"
     ]
    }
   ],
   "source": [
    "vertex_ai.init(\n",
    "    project=PROJECT,\n",
    "    location=REGION,\n",
    "    staging_bucket=BUCKET,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "run_id = f\"run-local-{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "vertex_ai.start_run(run_id)\n",
    "\n",
    "EXPERIMENT_RUN_DIR = os.path.join(EXPERIMENT_ARTIFACTS_DIR, EXPERIMENT_NAME, run_id)\n",
    "print(\"Experiment run directory:\", EXPERIMENT_RUN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c8cee2",
   "metadata": {},
   "source": [
    "## 1. Preprocess the data using Apache Beam\n",
    "\n",
    "The Apache Beam pipeline of data preprocessing is implemented in the [preprocessing](src/preprocessing) directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84a613a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORTED_DATA_PREFIX = os.path.join(EXPERIMENT_RUN_DIR, 'exported_data')\n",
    "TRANSFORMED_DATA_PREFIX = os.path.join(EXPERIMENT_RUN_DIR, 'transformed_data')\n",
    "TRANSFORM_ARTIFACTS_DIR = os.path.join(EXPERIMENT_RUN_DIR, 'transform_artifacts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264b81f3",
   "metadata": {},
   "source": [
    "### Get Source Query from Managed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9b8ad0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    SELECT \n",
      "        IF(trip_month IS NULL, -1, trip_month) trip_month,\n",
      "        IF(trip_day IS NULL, -1, trip_day) trip_day,\n",
      "        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\n",
      "        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\n",
      "        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\n",
      "        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\n",
      "        IF(payment_type IS NULL, 'NA', payment_type) payment_type,\n",
      "        IF(pickup_grid IS NULL, 'NA', pickup_grid) pickup_grid,\n",
      "        IF(dropoff_grid IS NULL, 'NA', dropoff_grid) dropoff_grid,\n",
      "        IF(euclidean IS NULL, -1, euclidean) euclidean,\n",
      "        IF(loc_cross IS NULL, 'NA', loc_cross) loc_cross,\n",
      "        tip_bin\n",
      "    FROM playground_us.chicago_taxitrips_prep \n",
      "    WHERE ML_use = 'UNASSIGNED'\n",
      "    LIMIT 5120\n"
     ]
    }
   ],
   "source": [
    "ML_USE = 'UNASSIGNED'\n",
    "LIMIT = 5120\n",
    "\n",
    "raw_data_query = datasource_utils.get_training_source_query(\n",
    "    project=PROJECT, \n",
    "    region=REGION, \n",
    "    dataset_display_name=DATASET_DISPLAY_NAME, \n",
    "    ml_use=ML_USE, \n",
    "    limit=LIMIT\n",
    ")\n",
    "\n",
    "print(raw_data_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6047eac1",
   "metadata": {},
   "source": [
    "### Test Data Preprocessing Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0db4462e-9c26-4086-a412-c4fe465573d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = {\n",
    "#     'runner': 'DirectRunner',\n",
    "#     'raw_data_query': raw_data_query,\n",
    "#     'write_raw_data': True,\n",
    "#     'exported_data_prefix': EXPORTED_DATA_PREFIX,\n",
    "#     'transformed_data_prefix': TRANSFORMED_DATA_PREFIX,\n",
    "#     'transform_artifact_dir': TRANSFORM_ARTIFACTS_DIR,\n",
    "#     'temporary_dir': os.path.join(WORKSPACE, 'tmp'),\n",
    "#     'gcs_location': f'gs://{BUCKET}/bq_tmp',\n",
    "#     'project': PROJECT\n",
    "# }\n",
    "\n",
    "args = {\n",
    "    'runner': 'DirectRunner',\n",
    "    'raw_data_query': raw_data_query,\n",
    "    'write_raw_data': True,\n",
    "    'exported_data_prefix': EXPORTED_DATA_PREFIX,\n",
    "    'transformed_data_prefix': TRANSFORMED_DATA_PREFIX,\n",
    "    'transform_artifact_dir': TRANSFORM_ARTIFACTS_DIR,\n",
    "    'temporary_dir': os.path.join(WORKSPACE, 'tmp'),\n",
    "    'gcs_location': BUCKET_URI,\n",
    "    'project': PROJECT\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c225f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.log_params(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56ece730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing started...\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery.py:2485: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  temp_location = pcoll.pipeline.options.view_as(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n",
      "INFO:absl:Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "2023-05-18 01:47:11.700826: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_transform/tf_utils.py:324: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 01:47:11.712611: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 01:47:11.714309: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 01:47:11.717210: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-18 01:47:11.718435: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 01:47:11.720118: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 01:47:11.721765: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 01:47:12.476094: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 01:47:12.478051: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 01:47:12.479666: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 01:47:12.481206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13582 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_transform/tf_utils.py:324: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n",
      "INFO:absl:Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature dropoff_grid_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature dropoff_grid_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature dropoff_grid_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature dropoff_grid_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature dropoff_grid_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds_xf has a shape . Setting to DenseTensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n",
      "INFO:absl:Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature dropoff_grid_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature dropoff_grid_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature dropoff_grid_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature dropoff_grid_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature dropoff_grid_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding invalid overrides: {'raw_data_query': \"\\n    SELECT \\n        IF(trip_month IS NULL, -1, trip_month) trip_month,\\n        IF(trip_day IS NULL, -1, trip_day) trip_day,\\n        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\\n        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\\n        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\\n        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\\n        IF(payment_type IS NULL, 'NA', payment_type) payment_type,\\n        IF(pickup_grid IS NULL, 'NA', pickup_grid) pickup_grid,\\n        IF(dropoff_grid IS NULL, 'NA', dropoff_grid) dropoff_grid,\\n        IF(euclidean IS NULL, -1, euclidean) euclidean,\\n        IF(loc_cross IS NULL, 'NA', loc_cross) loc_cross,\\n        tip_bin\\n    FROM playground_us.chicago_taxitrips_prep \\n    WHERE ML_use = 'UNASSIGNED'\\n    LIMIT 5120\", 'write_raw_data': True, 'exported_data_prefix': 'gs://vertex-mlops-chicago-taxi-bucket/chicago-taxi-tips/experiments/chicago-taxi-tips-classifier-v01/run-local-20230518014659/exported_data', 'transformed_data_prefix': 'gs://vertex-mlops-chicago-taxi-bucket/chicago-taxi-tips/experiments/chicago-taxi-tips-classifier-v01/run-local-20230518014659/transformed_data', 'transform_artifact_dir': 'gs://vertex-mlops-chicago-taxi-bucket/chicago-taxi-tips/experiments/chicago-taxi-tips-classifier-v01/run-local-20230518014659/transform_artifacts', 'temporary_dir': 'gs://vertex-mlops-chicago-taxi-bucket/chicago-taxi-tips/tmp', 'gcs_location': 'gs://vertex-mlops-chicago-taxi-bucket'}\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function annotate_downstream_side_inputs at 0x7f61e2b224d0> ====================\n",
      "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function fix_side_input_pcoll_coders at 0x7f61e2b225f0> ====================\n",
      "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function pack_combiners at 0x7f61e2b22b00> ====================\n",
      "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function lift_combiners at 0x7f61e2b22b90> ====================\n",
      "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function expand_sdf at 0x7f61e2b22d40> ====================\n",
      "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function expand_gbk at 0x7f61e2b22dd0> ====================\n",
      "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function sink_flattens at 0x7f61e2b22ef0> ====================\n",
      "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function greedily_fuse at 0x7f61e2b22f80> ====================\n",
      "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function read_to_impulse at 0x7f61e2b23050> ====================\n",
      "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function impulse_to_input at 0x7f61e2b230e0> ====================\n",
      "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function sort_stages at 0x7f61e2b23320> ====================\n",
      "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function add_impulse_to_dangling_transforms at 0x7f61e2b23440> ====================\n",
      "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function setup_timer_mapping at 0x7f61e2b23290> ====================\n",
      "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function populate_data_channel_coders at 0x7f61e2b233b0> ====================\n",
      "INFO:apache_beam.runners.worker.statecache:Creating state cache with size 104857600\n",
      "INFO:apache_beam.runners.portability.fn_api_runner.worker_handlers:Created Worker handler <apache_beam.runners.portability.fn_api_runner.worker_handlers.EmbeddedWorkerHandler object at 0x7f61f6376e90> for environment ref_Environment_default_environment_1 (beam:env:embedded_python:v1, b'')\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:absl:Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gs:/vertex-mlops-chicago-taxi-bucket/chicago-taxi-tips/tmp/tftransform_tmp/4e231baf8fb44074a1d98b3227785cdc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gs:/vertex-mlops-chicago-taxi-bucket/chicago-taxi-tips/tmp/tftransform_tmp/4e231baf8fb44074a1d98b3227785cdc/assets\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:apache_beam.internal.gcp.auth:Setting socket default timeout to 60 seconds.\n",
      "INFO:apache_beam.internal.gcp.auth:socket default timeout is 60.0 seconds.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Started BigQuery job: <JobReference\n",
      " location: 'US'\n",
      " projectId: 'g360-docai'>\n",
      " bq show -j --format=prettyjson --project_id=g360-docai None\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'playground_us'\n",
      " projectId: 'g360-docai'\n",
      " tableId: 'chicago_taxitrips_prep'> referenced by query \n",
      "    SELECT \n",
      "        IF(trip_month IS NULL, -1, trip_month) trip_month,\n",
      "        IF(trip_day IS NULL, -1, trip_day) trip_day,\n",
      "        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\n",
      "        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\n",
      "        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\n",
      "        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\n",
      "        IF(payment_type IS NULL, 'NA', payment_type) payment_type,\n",
      "        IF(pickup_grid IS NULL, 'NA', pickup_grid) pickup_grid,\n",
      "        IF(dropoff_grid IS NULL, 'NA', dropoff_grid) dropoff_grid,\n",
      "        IF(euclidean IS NULL, -1, euclidean) euclidean,\n",
      "        IF(loc_cross IS NULL, 'NA', loc_cross) loc_cross,\n",
      "        tip_bin\n",
      "    FROM playground_us.chicago_taxitrips_prep \n",
      "    WHERE ML_use = 'UNASSIGNED'\n",
      "    LIMIT 5120\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Dataset g360-docai:beam_temp_dataset_ee981ce748df40599165dcb6d9c5a605 does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Started BigQuery job: <JobReference\n",
      " jobId: 'beam_bq_job_QUERY_BQ_EXPORT_JOB_9663c067-5_1684374442_153'\n",
      " location: 'US'\n",
      " projectId: 'g360-docai'>\n",
      " bq show -j --format=prettyjson --project_id=g360-docai beam_bq_job_QUERY_BQ_EXPORT_JOB_9663c067-5_1684374442_153\n",
      "INFO:root:Job status: RUNNING\n",
      "INFO:root:Job status: DONE\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Started BigQuery job: <JobReference\n",
      " jobId: 'beam_bq_job_EXPORT_BQ_EXPORT_JOB_9663c067-5_1684374448_253'\n",
      " location: 'US'\n",
      " projectId: 'g360-docai'>\n",
      " bq show -j --format=prettyjson --project_id=g360-docai beam_bq_job_EXPORT_BQ_EXPORT_JOB_9663c067-5_1684374448_253\n",
      "INFO:root:Job status: RUNNING\n",
      "INFO:root:Job status: DONE\n",
      "INFO:apache_beam.io.gcp.gcsio:Finished listing 1 files in 0.0658724308013916 seconds.\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n",
      "WARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n",
      "INFO:root:BatchElements statistics: element_count=4109 batch_count=15 next_batch_size=672 timings=[(1, 0.009920120239257812), (2, 0.00941157341003418), (4, 0.008904218673706055), (8, 0.009274721145629883), (16, 0.010101079940795898), (32, 0.011578798294067383), (64, 0.012994766235351562), (128, 0.013364076614379883), (256, 0.016842365264892578), (512, 0.021605968475341797), (1000, 0.031092405319213867), (835, 0.028223276138305664), (914, 0.028034448623657227), (336, 0.015291690826416016)]\n",
      "INFO:root:BatchElements statistics: element_count=4109 batch_count=15 next_batch_size=370 timings=[(1, 0.0017278194427490234), (2, 0.0005736351013183594), (4, 0.0005834102630615234), (8, 0.0006501674652099609), (16, 0.0009763240814208984), (32, 0.002287626266479492), (64, 0.0013644695281982422), (128, 0.0017042160034179688), (256, 0.0030443668365478516), (512, 0.0041961669921875), (1000, 0.007907867431640625), (900, 0.00758051872253418), (1000, 0.006848335266113281), (185, 0.0020453929901123047)]\n",
      "INFO:root:BatchElements statistics: element_count=1011 batch_count=17 next_batch_size=102 timings=[(1, 0.0005846023559570312), (2, 0.0015177726745605469), (1, 0.0005376338958740234), (2, 0.0005888938903808594), (2, 0.0006046295166015625), (4, 0.0007054805755615234), (8, 0.0009815692901611328), (16, 0.0009479522705078125), (32, 0.000986337661743164), (64, 0.0015904903411865234), (128, 0.0038309097290039062), (139, 0.002024412155151367), (144, 0.0016498565673828125), (227, 0.002574443817138672), (189, 0.0018515586853027344), (51, 0.0009272098541259766)]\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:apache_beam.io.gcp.gcsio:Finished listing 1 files in 0.044052839279174805 seconds.\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:BatchElements statistics: element_count=8 batch_count=1 next_batch_size=150000 timings=[]\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:BatchElements statistics: element_count=31 batch_count=1 next_batch_size=150000 timings=[]\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:BatchElements statistics: element_count=7 batch_count=1 next_batch_size=150000 timings=[]\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:BatchElements statistics: element_count=24 batch_count=1 next_batch_size=150000 timings=[]\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:BatchElements statistics: element_count=6 batch_count=1 next_batch_size=150000 timings=[]\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:BatchElements statistics: element_count=2 batch_count=1 next_batch_size=150000 timings=[]\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:BatchElements statistics: element_count=3 batch_count=1 next_batch_size=150000 timings=[]\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:BatchElements statistics: element_count=5 batch_count=1 next_batch_size=150000 timings=[]\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gs:/vertex-mlops-chicago-taxi-bucket/chicago-taxi-tips/tmp/tftransform_tmp/4fc0b86a6b6f43e582fb669221c5a6e1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gs:/vertex-mlops-chicago-taxi-bucket/chicago-taxi-tips/tmp/tftransform_tmp/4fc0b86a6b6f43e582fb669221c5a6e1/assets\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.46.0\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing completed.\n"
     ]
    }
   ],
   "source": [
    "print(\"Data preprocessing started...\")\n",
    "etl.run_transform_pipeline(args)\n",
    "print(\"Data preprocessing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a10911e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommandException: One or more URLs matched no objects.\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls {EXPERIMENT_RUN_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d252ab",
   "metadata": {},
   "source": [
    "## 2. Train a custom model locally using a Keras\n",
    "\n",
    "The `Keras` implementation of the custom model is in the [model_training](src/model_training) directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59f7710",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = os.path.join(EXPERIMENT_RUN_DIR, 'logs')\n",
    "EXPORT_DIR = os.path.join(EXPERIMENT_RUN_DIR, 'model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a212f14",
   "metadata": {},
   "source": [
    "### Read transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204c8580",
   "metadata": {},
   "outputs": [],
   "source": [
    "tft_output = tft.TFTransformOutput(TRANSFORM_ARTIFACTS_DIR)\n",
    "transform_feature_spec = tft_output.transformed_feature_spec()\n",
    "transform_feature_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0802ce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file_pattern = os.path.join(TRANSFORMED_DATA_PREFIX,'train/data-*.gz')\n",
    "eval_data_file_pattern = os.path.join(TRANSFORMED_DATA_PREFIX,'eval/data-*.gz')\n",
    "\n",
    "for input_features, target in data.get_dataset(\n",
    "    train_data_file_pattern, transform_feature_spec, batch_size=3).take(1):\n",
    "    for key in input_features:\n",
    "        print(f\"{key} {input_features[key].dtype}: {input_features[key].numpy().tolist()}\")\n",
    "    print(f\"target: {target.numpy().tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f363d4",
   "metadata": {},
   "source": [
    "### Create hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fced82",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    \"hidden_units\": [64, 32]\n",
    "}\n",
    "\n",
    "hyperparams = defaults.update_hyperparams(hyperparams)\n",
    "hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c17b65e",
   "metadata": {},
   "source": [
    "### Create and test model inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05b0f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = model.create_binary_classifier(tft_output, hyperparams)\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4d33eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(\n",
    "    classifier, \n",
    "    show_shapes=True, \n",
    "    show_dtype=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06e056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(input_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d451ef7",
   "metadata": {},
   "source": [
    "### Train the model locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153efc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "hyperparams[\"learning_rate\"] = 0.001\n",
    "hyperparams[\"num_epochs\"] = 5\n",
    "hyperparams[\"batch_size\"] = 512\n",
    "\n",
    "vertex_ai.log_params(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91c4924",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = trainer.train(\n",
    "    train_data_dir=train_data_file_pattern,\n",
    "    eval_data_dir=eval_data_file_pattern,\n",
    "    tft_output_dir=TRANSFORM_ARTIFACTS_DIR,\n",
    "    hyperparams=hyperparams,\n",
    "    log_dir=LOG_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbce8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_accuracy = trainer.evaluate(\n",
    "    model=classifier,\n",
    "    data_dir=eval_data_file_pattern,\n",
    "    raw_schema_location=RAW_SCHEMA_LOCATION,\n",
    "    tft_output_dir=TRANSFORM_ARTIFACTS_DIR,\n",
    "    hyperparams=hyperparams,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e58239",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.log_metrics(\n",
    "    {\"val_loss\": val_loss, \"val_accuracy\": val_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff3c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tb-gcp-uploader --tensorboard_resource_name={tensorboard_resource_name} \\\n",
    "  --logdir={LOG_DIR} \\\n",
    "  --experiment_name={EXPERIMENT_NAME} --one_shot=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44268d04",
   "metadata": {},
   "source": [
    "### Export the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cf46d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_dir = os.path.join(EXPORT_DIR)\n",
    "\n",
    "exporter.export_serving_model(\n",
    "    classifier=classifier,\n",
    "    serving_model_dir=saved_model_dir,\n",
    "    raw_schema_location=RAW_SCHEMA_LOCATION,\n",
    "    tft_output_dir=TRANSFORM_ARTIFACTS_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba1ba3e",
   "metadata": {},
   "source": [
    "### Inspect model serving signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8989c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir={saved_model_dir} --tag_set=serve --signature_def=serving_tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7517a78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir={saved_model_dir} --tag_set=serve --signature_def=serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f68ecd0",
   "metadata": {},
   "source": [
    "### Test the exported SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965d7d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_model = tf.saved_model.load(saved_model_dir)\n",
    "print(\"Saved model is loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395f6ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the serving_tf_example with TF Examples\n",
    "\n",
    "file_names = tf.data.TFRecordDataset.list_files(EXPORTED_DATA_PREFIX + '/data-*.tfrecord')\n",
    "for batch in tf.data.TFRecordDataset(file_names).batch(3).take(1):\n",
    "    predictions = serving_model.signatures['serving_tf_example'](batch)\n",
    "    for key in predictions:\n",
    "        print(f\"{key}: {predictions[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f041d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the serving_default with feature dictionary\n",
    "\n",
    "import tensorflow_data_validation as tfdv\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "\n",
    "raw_schema = tfdv.load_schema_text(RAW_SCHEMA_LOCATION)\n",
    "raw_feature_spec = schema_utils.schema_as_feature_spec(raw_schema).feature_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d51e9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = {\n",
    "    \"dropoff_grid\": \"POINT(-87.6 41.9)\",\n",
    "    \"euclidean\": 2064.2696,\n",
    "    \"loc_cross\": \"\",\n",
    "    \"payment_type\": \"Credit Card\",\n",
    "    \"pickup_grid\": \"POINT(-87.6 41.9)\",\n",
    "    \"trip_miles\": 1.37,\n",
    "    \"trip_day\": 12,\n",
    "    \"trip_hour\": 6,\n",
    "    \"trip_month\": 2,\n",
    "    \"trip_day_of_week\": 4,\n",
    "    \"trip_seconds\": 555,\n",
    "}\n",
    "\n",
    "for feature_name in instance:\n",
    "    dtype = raw_feature_spec[feature_name].dtype\n",
    "    instance[feature_name] = tf.constant([[instance[feature_name]]], dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6469de0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = serving_model.signatures['serving_default'](**instance)\n",
    "for key in predictions:\n",
    "    print(f\"{key}: {predictions[key].numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cec2080",
   "metadata": {},
   "source": [
    "## Start a new Vertex AI experiment run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d87d0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.init(\n",
    "    project=PROJECT,\n",
    "    staging_bucket=BUCKET,\n",
    "    experiment=EXPERIMENT_NAME)\n",
    "\n",
    "run_id = f\"run-gcp-{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "vertex_ai.start_run(run_id)\n",
    "\n",
    "EXPERIMENT_RUN_DIR = os.path.join(EXPERIMENT_ARTIFACTS_DIR, EXPERIMENT_NAME, run_id)\n",
    "print(\"Experiment run directory:\", EXPERIMENT_RUN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ade27b7",
   "metadata": {},
   "source": [
    "## 3. Submit a Data Processing Job to Dataflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d903ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORTED_DATA_PREFIX = os.path.join(EXPERIMENT_RUN_DIR, 'exported_data')\n",
    "TRANSFORMED_DATA_PREFIX = os.path.join(EXPERIMENT_RUN_DIR, 'transformed_data')\n",
    "TRANSFORM_ARTIFACTS_DIR = os.path.join(EXPERIMENT_RUN_DIR, 'transform_artifacts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fac3380",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_USE = 'UNASSIGNED'\n",
    "LIMIT = 1000000\n",
    "raw_data_query = datasource_utils.get_training_source_query(\n",
    "    project=PROJECT, \n",
    "    region=REGION, \n",
    "    dataset_display_name=DATASET_DISPLAY_NAME, \n",
    "    ml_use=ML_USE, \n",
    "    limit=LIMIT\n",
    ")\n",
    "\n",
    "etl_job_name = f\"etl-{MODEL_DISPLAY_NAME}-{run_id}\"\n",
    "\n",
    "args = {\n",
    "    'job_name': etl_job_name,\n",
    "    'runner': 'DataflowRunner',\n",
    "    'raw_data_query': raw_data_query,\n",
    "    'exported_data_prefix': EXPORTED_DATA_PREFIX,\n",
    "    'transformed_data_prefix': TRANSFORMED_DATA_PREFIX,\n",
    "    'transform_artifact_dir': TRANSFORM_ARTIFACTS_DIR,\n",
    "    'write_raw_data': False,\n",
    "    'temporary_dir': os.path.join(WORKSPACE, 'tmp'),\n",
    "    'gcs_location': os.path.join(WORKSPACE, 'bq_tmp'),\n",
    "    'project': PROJECT,\n",
    "    'region': REGION,\n",
    "    'setup_file': './setup.py'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c909d3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.log_params(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014e5512",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "print(\"Data preprocessing started...\")\n",
    "etl.run_transform_pipeline(args)\n",
    "print(\"Data preprocessing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a21c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls {EXPERIMENT_RUN_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c4dfa8",
   "metadata": {},
   "source": [
    "## 4. Submit a Custom Training Job to Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50db6947",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = os.path.join(EXPERIMENT_RUN_DIR, 'logs')\n",
    "EXPORT_DIR = os.path.join(EXPERIMENT_RUN_DIR, 'model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e998139",
   "metadata": {},
   "source": [
    "### Test the training task locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9382ba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m src.model_training.task \\\n",
    "    --model-dir={EXPORT_DIR} \\\n",
    "    --log-dir={LOG_DIR} \\\n",
    "    --train-data-dir={TRANSFORMED_DATA_PREFIX}/train/* \\\n",
    "    --eval-data-dir={TRANSFORMED_DATA_PREFIX}/eval/*  \\\n",
    "    --tft-output-dir={TRANSFORM_ARTIFACTS_DIR} \\\n",
    "    --num-epochs=3 \\\n",
    "    --hidden-units=32,32 \\\n",
    "    --experiment-name={EXPERIMENT_NAME} \\\n",
    "    --run-name={run_id} \\\n",
    "    --project={PROJECT} \\\n",
    "    --region={REGION} \\\n",
    "    --staging-bucket={BUCKET}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5077e9d4",
   "metadata": {},
   "source": [
    "### Prepare training package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d526a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINER_PACKAGE_DIR = os.path.join(WORKSPACE, 'trainer_packages')\n",
    "TRAINER_PACKAGE_NAME = f'{MODEL_DISPLAY_NAME}_trainer'\n",
    "print(\"Trainer package upload location:\", TRAINER_PACKAGE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550cc9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r src/__pycache__/\n",
    "!rm -r src/.ipynb_checkpoints/\n",
    "!rm -r src/raw_schema/.ipynb_checkpoints/\n",
    "!rm -f {TRAINER_PACKAGE_NAME}.tar {TRAINER_PACKAGE_NAME}.tar.gz\n",
    "\n",
    "!mkdir {TRAINER_PACKAGE_NAME}\n",
    "\n",
    "!cp setup.py {TRAINER_PACKAGE_NAME}/\n",
    "!cp -r src {TRAINER_PACKAGE_NAME}/\n",
    "!tar cvf {TRAINER_PACKAGE_NAME}.tar {TRAINER_PACKAGE_NAME}\n",
    "!gzip {TRAINER_PACKAGE_NAME}.tar\n",
    "!gsutil cp {TRAINER_PACKAGE_NAME}.tar.gz {TRAINER_PACKAGE_DIR}/\n",
    "!rm -r {TRAINER_PACKAGE_NAME}\n",
    "!rm -r {TRAINER_PACKAGE_NAME}.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3af757",
   "metadata": {},
   "source": [
    "### Prepare the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01bf43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_RUNTIME = 'tf-cpu.2-5'\n",
    "TRAIN_IMAGE = f\"us-docker.pkg.dev/vertex-ai/training/{TRAIN_RUNTIME}:latest\"\n",
    "print(\"Training image:\", TRAIN_IMAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d18dba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "hidden_units = \"64,64\"\n",
    "\n",
    "trainer_args = [\n",
    "    f'--train-data-dir={TRANSFORMED_DATA_PREFIX + \"/train/*\"}',\n",
    "    f'--eval-data-dir={TRANSFORMED_DATA_PREFIX + \"/eval/*\"}',\n",
    "    f'--tft-output-dir={TRANSFORM_ARTIFACTS_DIR}',\n",
    "    f'--num-epochs={num_epochs}',\n",
    "    f'--learning-rate={learning_rate}',\n",
    "    f'--project={PROJECT}',\n",
    "    f'--region={REGION}',\n",
    "    f'--staging-bucket={BUCKET}',\n",
    "    f'--experiment-name={EXPERIMENT_NAME}'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a30d0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "package_uri = os.path.join(TRAINER_PACKAGE_DIR, f'{TRAINER_PACKAGE_NAME}.tar.gz')\n",
    "\n",
    "worker_pool_specs = [\n",
    "    {\n",
    "        \"replica_count\": 1,\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": 'n1-standard-4',\n",
    "            \"accelerator_count\": 0\n",
    "    },\n",
    "        \"python_package_spec\": {\n",
    "            \"executor_image_uri\": TRAIN_IMAGE,\n",
    "            \"package_uris\": [package_uri],\n",
    "            \"python_module\": \"src.model_training.task\",\n",
    "            \"args\": trainer_args,\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788d6e99",
   "metadata": {},
   "source": [
    "### Submit the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4544105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Submitting a custom training job...\")\n",
    "\n",
    "training_job_display_name = f\"{TRAINER_PACKAGE_NAME}_{run_id}\"\n",
    "\n",
    "training_job = vertex_ai.CustomJob(\n",
    "    display_name=training_job_display_name,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    base_output_dir=EXPERIMENT_RUN_DIR,\n",
    ")\n",
    "\n",
    "training_job.run(\n",
    "    service_account=SERVICE_ACCOUNT,\n",
    "    tensorboard=tensorboard_resource_name,\n",
    "    sync=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2896b59",
   "metadata": {},
   "source": [
    "## 5. Upload exported model to Vertex AI Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86b288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls {EXPORT_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40e0c39",
   "metadata": {},
   "source": [
    "### Generate the Explanation metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d5df4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_config = features.generate_explanation_config()\n",
    "explanation_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cd0587",
   "metadata": {},
   "source": [
    "### Upload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d0dbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVING_RUNTIME='tf2-cpu.2-5'\n",
    "SERVING_IMAGE = f\"us-docker.pkg.dev/vertex-ai/prediction/{SERVING_RUNTIME}:latest\"\n",
    "print(\"Serving image:\", SERVING_IMAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b24abd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_metadata = vertex_ai.explain.ExplanationMetadata(\n",
    "    inputs=explanation_config[\"inputs\"],\n",
    "    outputs=explanation_config[\"outputs\"],\n",
    ")\n",
    "explanation_parameters = vertex_ai.explain.ExplanationParameters(\n",
    "    explanation_config[\"params\"]\n",
    ")\n",
    "\n",
    "vertex_model = vertex_ai.Model.upload(\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    artifact_uri=EXPORT_DIR,\n",
    "    serving_container_image_uri=SERVING_IMAGE,\n",
    "    parameters_schema_uri=None,\n",
    "    instance_schema_uri=None,\n",
    "    explanation_metadata=explanation_metadata,\n",
    "    explanation_parameters=explanation_parameters,\n",
    "    labels={\n",
    "        'dataset_name': DATASET_DISPLAY_NAME,\n",
    "        'experiment': run_id\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51756dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_model.gca_resource"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa55220",
   "metadata": {},
   "source": [
    "## 6. Extract experiment run parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07808f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df = vertex_ai.get_experiment_df()\n",
    "experiment_df = experiment_df[experiment_df.experiment_name == EXPERIMENT_NAME]\n",
    "experiment_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367183aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vertex AI Experiments:\")\n",
    "print(\n",
    "    f\"https://console.cloud.google.com/vertex-ai/locations{REGION}/experiments/{EXPERIMENT_NAME}/metrics?project={PROJECT}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96618f6",
   "metadata": {},
   "source": [
    "## 7. Submit a Hyperparameter Tuning Job to Vertex AI\n",
    "\n",
    "For more information about configuring a hyperparameter study, refer to [Vertex AI Hyperparameter job configuration](https://cloud.google.com/vertex-ai/docs/training/using-hyperparameter-tuning)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1b87cd",
   "metadata": {},
   "source": [
    "### Configure a hyperparameter job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ffa249",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_spec = {\n",
    "    'ACCURACY': 'maximize'\n",
    "}\n",
    "\n",
    "parameter_spec = {\n",
    "    'learning-rate': hp_tuning.DoubleParameterSpec(min=0.0001, max=0.01, scale='log'),\n",
    "    'hidden-units': hp_tuning.CategoricalParameterSpec(values=[\"32,32\", \"64,64\", \"128,128\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2454dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_job_display_name = f\"hpt_{TRAINER_PACKAGE_NAME}_{run_id}\"\n",
    "\n",
    "hp_tuning_job = vertex_ai.HyperparameterTuningJob(\n",
    "    display_name=tuning_job_display_name,\n",
    "    custom_job=training_job,\n",
    "    metric_spec=metric_spec,\n",
    "    parameter_spec=parameter_spec,\n",
    "    max_trial_count=4,\n",
    "    parallel_trial_count=2,\n",
    "    search_algorithm=None # Bayesian optimization.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e4ee22",
   "metadata": {},
   "source": [
    "### Submit the hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5b434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Submitting a hyperparameter tunning job...\")\n",
    "\n",
    "hp_tuning_job.run(\n",
    "    service_account=SERVICE_ACCOUNT,\n",
    "    tensorboard=tensorboard_resource_name,\n",
    "    restart_job_on_worker_restart=False,\n",
    "    sync=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fd20da",
   "metadata": {},
   "source": [
    "### Retrieve trial results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8352e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_tuning_job.trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311922be",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = sorted(\n",
    "    hp_tuning_job.trials, \n",
    "    key=lambda trial: trial.final_measurement.metrics[0].value, \n",
    "    reverse=True\n",
    ")[0]\n",
    "\n",
    "print(\"Best trial ID:\", best_trial.id)\n",
    "print(\"Validation Accuracy:\", best_trial.final_measurement.metrics[0].value)\n",
    "print(\"Hyperparameter Values:\")\n",
    "for parameter in best_trial.parameters:\n",
    "    print(f\" - {parameter.parameter_id}:{parameter.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e88555c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
